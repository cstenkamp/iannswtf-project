DONE:
-we have pre-trained word embeddings!
-word2vec in eine eigene Klasse/Funktion
-word2vec lernt auf train UND test set
-beide sets im programflow einlesen, damit das testen leichter geht
-das end-token adden BEVOR word2vec läuft
-einen viel-zeit-modus machen, wo er train und test accuracy live errechnet und direkt plottet und man sich das beste aussuchen kann
-funktion um einzelne Ratings zu geben
-die word2vec-embeddings tatsächlich nutzen
-gucken wie man weights speichert

TODO:
-das shortenstrings zieht noch sätze auseinander!! >.<
-beim viel-zeit-modus noch ganz viele einzelne weights speichern (nach jeder iteration)
-oh, achja, mit pretrained wordvecs klappts noch nicht (???)
-dann das generative model.
-ersetzt er im trumpdataset bisher überhaupt durch <unk>?
-warum ist "nwed" eines der häufigsten wörter??

GENERELL
-das bisherige guuut auskommentieren
-quellen mitscheiben
-mitschreiben was suboptimal ist (auch was gut, word2vec selbstcoden)
-gucken ob der beim twitter-set "4" und "for" nah beieinander macht :o
-word2vec anschließend nen bisschen clustern? sodass colloquial-synonyme einfacher zu erkennen sind?
-wie gehen wir mit @mention's um?
-nen super-expressive-run-modus, wo der schön die kurve mit testing und training loss anzeigt!
-vielleicht vielleicht vielleicht usernamen durch nen generelles user-token ersetzen? Oder nach kategorie? Oder 2: retweet, antweet?
-den langen expressive mode (siehe erwartungshorizont)
-einen generator schreiben der zufällige strings macht, und das halt als negative input für GAN??