TODO-AKTUELL
-die ganzen inputs optional als parameter
-expressive mode noch besser, mit optionalen parametern überall was er printen soll
-den graph im expressive mode noch labeln
-noch nen plot für die lange generator-version
-word2vec noch für den generator
-die beiden validates thrown noch wenn kein dataset da ist
-EInstellen können ob er posts mit @ am anfang [und mit @ überhaupt] will


DONE:
-we have pre-trained word embeddings!
-word2vec in eine eigene Klasse/Funktion
-word2vec lernt auf train UND test set
-beide sets im programflow einlesen, damit das testen leichter geht
-das end-token adden BEVOR word2vec läuft
-einen viel-zeit-modus machen, wo er train und test accuracy live errechnet und direkt plottet und man sich das beste aussuchen kann
-funktion um einzelne Ratings zu geben
-die word2vec-embeddings tatsächlich nutzen
-gucken wie man weights speichert
-beim viel-zeit-modus noch ganz viele einzelne weights speichern (nach jeder iteration)
-oh, achja, mit pretrained wordvecs klappts noch nicht (???)
-dann das generative model.
-ersetzt er im trumpdataset bisher überhaupt durch <unk>?
-warum ist "nwed" eines der häufigsten wörter??
-gucken ob der beim twitter-set "4" und "for" nah beieinander macht :o
-den langen expressive mode (siehe erwartungshorizont)
-nen super-expressive-run-modus, wo der schön die kurve mit testing und training loss anzeigt!
-Die länge des strings per wahrscheinlichkeitsverteilung über dingsi
-einen generator schreiben der zufällige strings macht, und das halt als negative input für GAN??


TODO:
-das shortenstrings zieht noch sätze auseinander!! >.<
-word2vec anschließend nen bisschen clustern? sodass colloquial-synonyme einfacher zu erkennen sind?
-nach dem generator muss noch ein skript laufen dass die <unks> wegmacht, falls sie mitgeneriert wurden


GENERELL
-das bisherige guuut auskommentieren
-quellen mitscheiben
-mitschreiben was suboptimal ist (auch was gut, word2vec selbstcoden)
-wie gehen wir mit @mention's um?
-vielleicht vielleicht vielleicht usernamen durch nen generelles user-token ersetzen? Oder nach kategorie? Oder 2: retweet, antweet?


WE SEE
-when using pretrained w2v, it starts at 75% accuracy!
-4 und for sind nah